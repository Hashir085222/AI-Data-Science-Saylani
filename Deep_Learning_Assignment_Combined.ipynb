{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f65245",
   "metadata": {},
   "source": [
    "# Task 1: Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c7907-a06f-47fa-9abc-c79dbcb74996",
   "metadata": {},
   "source": [
    "##Task 1: Artificial Neural Network (ANN)\n",
    "\n",
    "##Task Description\n",
    "##Design and implement a basic Artificial Neural Network (ANN) using a tabular dataset.\n",
    "##Explanation\n",
    "##In this task, students are expected to understand how a simple neural network works with numerical or categorical data. Students should:\n",
    "##Select a suitable tabular dataset (e.g., student performance, medical data, house prices).\n",
    "\n",
    "##Perform data preprocessing such as:\n",
    "##Handling missing values\n",
    "##Feature scaling (normalization or standardization)\n",
    "##Encoding categorical variables\n",
    "##Design an ANN with:\n",
    "##Input layer\n",
    "##At least one hidden layer\n",
    "##Output layer\n",
    "##Train the model and evaluate it using appropriate metrics such as accuracy or mean squared error (MSE).\n",
    "##Explain:\n",
    "##The ANN architecture\n",
    "##Activation functions used\n",
    "##Loss function and optimizer selection\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2857475d-fa46-44df-b21e-74b4a660fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de9ea2a-b6d3-4843-9d10-f5e0031ee23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.964799 -0.066449  0.986768 -0.358079  0.997266  1.181890 -1.615679   \n",
      "1 -0.916511 -0.566395 -1.008614  0.831617 -1.176962  1.820544  1.752375   \n",
      "2 -0.109484 -0.432774 -0.457649  0.793818 -0.268646 -1.836360  1.239086   \n",
      "3  1.750412  2.023606  1.688159  0.006800 -1.607661  0.184741 -2.619427   \n",
      "4 -0.224726 -0.711303 -0.220778  0.117124  1.536061  0.597538  0.348645   \n",
      "\n",
      "          7         8         9  target  \n",
      "0 -1.210161 -0.628077  1.227274       0  \n",
      "1 -0.984534  0.363896  0.209470       1  \n",
      "2 -0.246383 -1.058145 -0.297376       1  \n",
      "3 -0.357445 -1.473127 -0.190039       0  \n",
      "4 -0.939156  0.175915  0.236224       1  \n"
     ]
    }
   ],
   "source": [
    "#create Tabular Dataset:\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "data = pd.DataFrame(X)\n",
    "data[\"target\"] = y\n",
    "\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a76556-24df-4013-83f8-c7afbf0b07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "5         0\n",
      "6         0\n",
      "7         0\n",
      "8         0\n",
      "9         0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check missing Value:\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05b758e-3943-4a55-a4cf-9048d839dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 10)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "#Split Data:\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbd739c-0c1e-4e28-92f7-b0454a3d33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12539276 -0.20523516  0.18584842  0.09408965  0.59201466  1.59044423\n",
      "  -0.44274266  2.38779557  0.70707881  0.18766553]\n",
      " [-2.23457225  0.10723174 -2.01311623  0.49723662  2.38362435  0.38437143\n",
      "   1.60586952 -0.85677102  1.73874053  2.58453827]]\n"
     ]
    }
   ],
   "source": [
    "#feature Scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8868c1b8-10ae-4362-85ec-225e4aca9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Build ANN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\", input_shape=(10,)))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2bde76e-2fc4-4696-8df6-c103818fd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3107bb91-4f4a-4fbd-a639-7fe5abafc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6000 - loss: 0.6821\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.6055\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.5443\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.4943\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: 0.4530\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.4208\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8612 - loss: 0.3943\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3748\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3599\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3476\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3372\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3296\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3226\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.3173\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3129\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3094\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3065\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3034\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3009\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.2992\n"
     ]
    }
   ],
   "source": [
    "# 08 Train the Model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57196b4f-8811-4e53-bae7-7fd314e064e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Predicted values: [[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(\"Predicted values:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba5fdd5-f6ba-4bf7-878e-901b823b4ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Evalution Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ac13d-1e03-4b8d-9099-9b7552046abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9a9a7-9fbf-4ae3-9bc0-35654a1ab9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408631b-81b5-4575-a79f-5a3d59feee9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b0259-151e-4f53-a1f7-0e6c5f3e57f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e52dde-38b4-420e-ab3c-fedf2ba5092d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da85ddd9",
   "metadata": {},
   "source": [
    "# Task 2: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9e27c-fd66-468d-9d53-0aa4fd521e78",
   "metadata": {},
   "source": [
    "##Task 2: Convolutional Neural Network (CNN)\n",
    "Description\n",
    "Build a Convolutional Neural Network (CNN) for image classification using a publicly available dataset.\n",
    "Explanation\n",
    "This task introduces students to image-based deep learning. Students should:\n",
    "Use any public image dataset (e.g., animals, objects).\n",
    "\n",
    "\n",
    "Apply image preprocessing such as resizing and normalization.\n",
    "\n",
    "\n",
    "Design a CNN architecture including:\n",
    "\n",
    "\n",
    "Convolution layers\n",
    "\n",
    "\n",
    "Pooling layers\n",
    "\n",
    "\n",
    "Fully connected layers\n",
    "\n",
    "\n",
    "Train and test the model.\n",
    "\n",
    "\n",
    "Evaluate performance using:\n",
    "\n",
    "\n",
    "Accuracy\n",
    "\n",
    "\n",
    "Precision\n",
    "\n",
    "\n",
    "Recall\n",
    "\n",
    "\n",
    "F1-score\n",
    "\n",
    "\n",
    "Briefly explain what each evaluation metric indicates about model performance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005eedff-8e05-45a8-bb52-914fb3a31846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important Libraries:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3867b9d0-2189-4c39-bc08-d9ea9d1e09b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce so we will re-download the data.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "#Load the DataSet :\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824cf55c-6bae-465d-ad9c-f0230e6fb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing:\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e09f16b-d3c7-4710-9ac8-c24b162cfc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\newenv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Bulid the CNN Model:\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa08e21e-a235-4e0c-80eb-f880457b21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COmpile the Model:\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5caf07-0053-4903-89ab-9e7b99b7e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.4274 - loss: 1.5907 - val_accuracy: 0.5277 - val_loss: 1.3356\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.5696 - loss: 1.2245 - val_accuracy: 0.5878 - val_loss: 1.1770\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.6173 - loss: 1.0934 - val_accuracy: 0.6143 - val_loss: 1.1044\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.6506 - loss: 1.0022 - val_accuracy: 0.6488 - val_loss: 1.0208\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.6729 - loss: 0.9429 - val_accuracy: 0.6613 - val_loss: 0.9756\n"
     ]
    }
   ],
   "source": [
    "# Train the Model::\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdf1dd4-5589-444c-b236-dcc7acf039be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6598 - loss: 0.9797\n",
      "Test Accuracy: 0.6597999930381775\n"
     ]
    }
   ],
   "source": [
    "#Test the Model:\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b90f816-5381-476a-844b-d60727c38d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "#Prediction:\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b41110-abfb-4e12-9726-56f0a5b8eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6598\n",
      "Precision: 0.6643195481992752\n",
      "Recall: 0.6598\n",
      "F1 Score: 0.6572556657402485\n"
     ]
    }
   ],
   "source": [
    "#Evalution Matrics:\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8d577-1c32-4f88-ad90-ffff8654c547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da10d8-bc61-4e3c-a5d4-34abb4a4a1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d804889-a2d2-4379-bbf9-c0eab10b3978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4a5b9-ec77-4e67-9f88-1de60c2ffb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7349e82a",
   "metadata": {},
   "source": [
    "# Task 3: CNN-Based Image Recognition System using Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b94bb-ab21-47f5-b5b9-48528cc407d7",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d8fbe5-1096-406c-bde6-e230d8859607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f0b4d6-bcbe-4872-bff2-2077f6773e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18134d-3a0f-4b99-8a58-0f85bdef4d55",
   "metadata": {},
   "source": [
    "# Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfdde6f-3e25-46c4-961b-79d65311b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a0f23-cad7-4427-8a7b-bdf28035698b",
   "metadata": {},
   "source": [
    "# Data load and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47045376-8f59-4b6f-aed9-1cd94d077c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 835 images belonging to 3 classes.\n",
      "Found 206 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a19d7f33-7e5e-4414-8458-1f9607c829e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 29s 1s/step - loss: 1.7554 - accuracy: 0.4395 - val_loss: 0.7897 - val_accuracy: 0.7136\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 17s 627ms/step - loss: 0.7152 - accuracy: 0.6970 - val_loss: 0.5036 - val_accuracy: 0.7961\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 14s 516ms/step - loss: 0.4577 - accuracy: 0.8323 - val_loss: 0.3386 - val_accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 14s 517ms/step - loss: 0.2502 - accuracy: 0.9018 - val_loss: 0.3188 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.1694 - accuracy: 0.9401 - val_loss: 0.3140 - val_accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 14s 514ms/step - loss: 0.0921 - accuracy: 0.9784 - val_loss: 0.2666 - val_accuracy: 0.8932\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 14s 512ms/step - loss: 0.0636 - accuracy: 0.9880 - val_loss: 0.2440 - val_accuracy: 0.9223\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 14s 525ms/step - loss: 0.0466 - accuracy: 0.9892 - val_loss: 0.2788 - val_accuracy: 0.9078\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 14s 516ms/step - loss: 0.0268 - accuracy: 0.9952 - val_loss: 0.2460 - val_accuracy: 0.9272\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 14s 520ms/step - loss: 0.0197 - accuracy: 0.9988 - val_loss: 0.2651 - val_accuracy: 0.9223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164b9bd9240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827d2d9-bf5a-49a1-a0d9-b7cb20f51e26",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ac3f6a8-b56d-4872-80a1-9513f70b05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"face_recognition_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8c4b8-6ba4-42f3-8689-3fe299995e4e",
   "metadata": {},
   "source": [
    "# Flask Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8f985-2516-4548-a8a0-e5c2985ae020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # app.py (Flask Deployment Script)\n",
    "\n",
    "# from flask import Flask, render_template, request\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# app = Flask(__name__)\n",
    "# app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "\n",
    "# model = load_model('model.h5')\n",
    "# class_labels = ['Class_1', 'Class_2']\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     file = request.files['file']\n",
    "#     filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "#     file.save(filepath)\n",
    "\n",
    "#     img = image.load_img(filepath, target_size=(224, 224))\n",
    "#     img_array = image.img_to_array(img)\n",
    "#     img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "#     prediction = model.predict(img_array)\n",
    "#     result = class_labels[np.argmax(prediction)]\n",
    "\n",
    "#     return result\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
